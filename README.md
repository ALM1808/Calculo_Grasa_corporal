üß† Predicci√≥n de Porcentaje de Grasa Corporal (End-to-End MLOps)

Proyecto completo de ML + MLOps para predecir el porcentaje de grasa corporal a partir de datos de entrenamiento f√≠sico, integrando:

Ingesta y transformaci√≥n de datos

Entrenamiento de un modelo de Machine Learning con scikit-learn

Uso de Hopsworks como:

Feature Store

Model/Prediction tracking (via Feature Groups)

API backend con FastAPI

Frontend con Streamlit consumiendo la API

Notebook de monitorizaci√≥n y data drift

Este repositorio est√° dise√±ado como proyecto de curso / portfolio demostrando un flujo moderno de MLOps, pero funcionando tambi√©n en local.

üóÇ Estructura del proyecto
.
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                 # (Opcional) Versi√≥n legacy: Streamlit con modelo directo
‚îÇ   ‚îî‚îÄ‚îÄ api_client_app.py      # ‚úÖ Streamlit frontend que llama al backend FastAPI
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                # ‚úÖ API FastAPI (/predict, /feedback)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gym_members_exercise_tracking.csv
‚îÇ   ‚îú‚îÄ‚îÄ interim/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineered_data.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ preprocessed_data.csv
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ rf_pipeline.pkl        # ‚úÖ Pipeline entrenado (preprocesamiento + modelo)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb           # Exploraci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_train_pipeline.ipynb (opcional; ahora se usa script)
‚îÇ   ‚îî‚îÄ‚îÄ 09_monitoring.ipynb    # ‚úÖ Monitorizaci√≥n + drift
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ train_pipeline.py  # Entrena y guarda rf_pipeline.pkl
‚îÇ       ‚îî‚îÄ‚îÄ predict_model.py   # load_model() para backend
‚îú‚îÄ‚îÄ feature_store/             # Feature store local (opcional)
‚îú‚îÄ‚îÄ .env                       # üîê Variables de entorno (NO subir a GitHub)
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md

üìä 1. Datos

Dataset base: data/raw/gym_members_exercise_tracking.csv
Contiene informaci√≥n de usuarios de gimnasio:

Edad, g√©nero, peso, altura

Frecuencias card√≠acas (m√°x, media, reposo)

Duraci√≥n de sesi√≥n, tipo de entrenamiento

Consumo de agua, frecuencia de entrenamiento

Objetivo/√≠ndice de grasa corporal (Fat_Percentage)

Paso a paso (notebooks)

01_eda.ipynb

Carga el CSV

Revisa tipos, nulos, estad√≠sticas descriptivas

Primeras visualizaciones sencillas

02_feature_engineering.ipynb

Crea nuevas columnas:

BMI = peso / altura¬≤

Log_Age = log(edad)

Guarda resultado en:

data/interim/feature_engineered_data.csv

03_preprocessing.ipynb

Opcional seg√∫n versi√≥n.

En la versi√≥n estable actual:

El preprocesamiento se incorpora en el pipeline final en train_pipeline.py.

ü§ñ 2. Entrenamiento del modelo

El script principal es:

src/models/train_pipeline.py


Este script:

Lee data/interim/feature_engineered_data.csv.

Separa:

y = Fat_Percentage

X con el resto de columnas.

Detecta num√©ricas y categ√≥ricas.

Construye un Pipeline de sklearn:

ColumnTransformer(
  num -> StandardScaler,
  cat -> OneHotEncoder(handle_unknown="ignore")
)
+ RandomForestRegressor


Entrena con train_test_split.

Guarda el pipeline completo en:

models/rf_pipeline.pkl


Este pipeline incluye:

Preprocesamiento

Modelo

Soporte de columnas esperadas con nombres del dataset original:

"Age", "Gender", "Weight (kg)", "Height (m)", ... , "BMI", "Log_Age"

Despu√©s del entrenamiento, el backend solo necesita este .pkl.

üß© 3. Carga del modelo en producci√≥n

Archivo:

src/models/predict_model.py


Responsabilidad:

Localiza models/rf_pipeline.pkl.

Lo carga con joblib.

Expone load_model() para que el backend lo use.

üõ∞ 4. Backend: FastAPI

Archivo principal:

backend/main.py

Endpoints
GET /

Healthcheck sencillo:

{ "message": "API de predicci√≥n de grasa corporal üß†" }

POST /predict

Request JSON (snake_case, lo que env√≠a el frontend):

{
  "email": "user@example.com",
  "age": 35,
  "gender": "Male",
  "weight_kg": 75.0,
  "height_m": 1.78,
  "max_bpm": 180,
  "avg_bpm": 140,
  "resting_bpm": 65,
  "session_duration_hours": 1.2,
  "calories_burned": 520.5,
  "workout_type": "Mixed",
  "water_intake_liters": 2.0,
  "workout_frequency_days_week": 4,
  "experience_level": "2"
}


L√≥gica interna:

Valida con PredictionInput (Pydantic).

Calcula:

BMI

Log_Age

Traduce las columnas a los nombres que espera el modelo (SNAKE_TO_MODEL).

Ordena columnas seg√∫n EXPECTED_MODEL_COLS.

Usa load_model() para cargar rf_pipeline.pkl.

Devuelve:

{ "predicted_fat_percentage": 25.40 }


Adem√°s (si hay credenciales Hopsworks configuradas):

Registra la predicci√≥n en el Feature Group:

user_fat_percentage v1

POST /feedback

Para guardar el valor real enviado por el usuario cuando lo conozca:

{
  "email": "user@example.com",
  "real_fat_percentage": 24.5,
  "predicted_fat_percentage": 25.4
}


Guarda el feedback en:

user_fat_feedback v1

Esto permite evaluar el modelo con datos reales posteriormente.

üñ• 5. Frontend: Streamlit via API

Archivo principal recomendado:

app/api_client_app.py


Funciona as√≠:

Pide email y todas las variables de entrada.

Construye el JSON con los nombres EXACTOS que espera el backend.

Llama a:

POST http://localhost:8000/predict


Muestra la predicci√≥n al usuario.

Mantiene la √∫ltima predicci√≥n en st.session_state para:

Enviar feedback real (/feedback) cuando el usuario lo introduzca.

El frontend NO carga el modelo directamente:

Todo pasa por la API ‚Üí arquitectura limpia y desacoplada.

app/app.py queda como versi√≥n alternativa/hist√≥rica:

Streamlit cargando modelo directo/local/GitHub/Hopsworks.

No es necesario para la versi√≥n API-first.

üß± 6. Integraci√≥n con Hopsworks

Esta parte es opcional pero ya la tienes integrada y funcionando.

Feature Groups

user_fat_percentage v1

Contiene (formato snake_case):

Claves:

user_id, email, timestamp

Features:

age, gender, weight_kg, height_m, max_bpm, avg_bpm, resting_bpm, session_duration_hours, calories_burned, workout_type, water_intake_liters, workout_frequency_days_week, experience_level, bmi, log_age

Targets:

predicted_fat_percentage

real_fat_percentage (si se conoce)

Se escribe desde:

backend/main.py ‚Üí save_prediction_to_hopsworks()

user_fat_feedback v1

Contiene:

user_id, email, timestamp, real_fat_percentage, predicted_fat_percentage

Se escribe desde:

Endpoint /feedback

üìà 7. Monitorizaci√≥n & Data Drift

Notebook:

notebooks/09_monitoring.ipynb


Hace:

Carga user_fat_percentage y user_fat_feedback desde Hopsworks.

Une predicciones + valores reales (cuando existen).

Calcula m√©tricas b√°sicas del modelo:

MAE

RMSE

R¬≤

Detecta posibles se√±ales de data drift comparando:

Distribuciones hist√≥ricas vs recientes de features clave

Por ejemplo: edad, peso, BMI.

Muestra tablas/res√∫menes para explicar:

C√≥mo est√° funcionando el modelo en producci√≥n.

Si los usuarios actuales se parecen a los del entrenamiento.

Este notebook act√∫a como un dashboard interno sencillo de MLOps:

No afecta al usuario final.

Es perfecto para explicar en el curso/entrevista:

‚ÄúTengo monitorizaci√≥n b√°sica implementada sobre Feature Store‚Äù.

‚öôÔ∏è 8. C√≥mo ejecutar el proyecto en local
1Ô∏è‚É£ Clonar y entrar
git clone <tu_repo>
cd GRASACORPORAL

2Ô∏è‚É£ Crear entorno virtual
python -m venv .venv
.\.venv\Scripts\activate   # Windows PowerShell
# source .venv/bin/activate  # Linux/Mac

3Ô∏è‚É£ Instalar dependencias
pip install -r requirements.txt

4Ô∏è‚É£ Crear .env en la ra√≠z
HOPSWORKS_API_KEY=TU_API_KEY   # opcional; si no lo pones, simplemente no sube a Hopsworks
HOPSWORKS_PROJECT=GrasaCorporal
HOPSWORKS_HOST=c.app.hopsworks.ai


‚ö†Ô∏è No subas .env a GitHub.

5Ô∏è‚É£ Entrenar modelo (si no existe)
python -m src.models.train_pipeline
# genera models/rf_pipeline.pkl

6Ô∏è‚É£ Levantar el backend

Desde la ra√≠z del proyecto, con el entorno activo:

uvicorn backend.main:app --reload


La API estar√° en:

http://127.0.0.1:8000

Documentaci√≥n interactiva: http://127.0.0.1:8000/docs

7Ô∏è‚É£ Levantar el frontend (Streamlit)

En otra terminal (tambi√©n con .venv activado):

streamlit run app/api_client_app.py


Interact√∫as desde el navegador:

Introduces tus datos

Ves la predicci√≥n

(Opcional) Env√≠as feedback real

‚òÅÔ∏è 9. Despliegue (visi√≥n general)

La arquitectura est√° preparada para:

Backend FastAPI en un contenedor ‚Üí desplegable en:

Google Cloud Run

Render

Azure, etc.

Frontend Streamlit en otro contenedor independiente.

Ambos apuntando a:

Mismo modelo versionado

Mismo Feature Store en Hopsworks

La separaci√≥n Front / Back:

Permite escalar, monitorizar y actualizar el modelo sin tocar el frontend.

Demuestra buenas pr√°cticas MLOps.

üìù 10. Qu√© demuestra este proyecto

En una frase:

De datos crudos en CSV ‚Üí features ‚Üí modelo en pipeline ‚Üí API ‚Üí frontend separado ‚Üí logging en Feature Store ‚Üí monitorizaci√≥n.